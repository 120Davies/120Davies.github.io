{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ro_Davies_LS_DS_Unit_4_Sprint_Challenge_2 (1).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "nteract": {
      "version": "0.15.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/120Davies/120Davies.github.io/blob/master/Ro_Davies_LS_DS_Unit_4_Sprint_Challenge_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rUFvihI0AFGM"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2*\n",
        "\n",
        "# Sprint Challenge - Neural Network Foundations\n",
        "\n",
        "Table of Problems\n",
        "\n",
        "1. [Defining Neural Networks](#Q1)\n",
        "2. [Chocolate Gummy Bears](#Q2)\n",
        "    - Perceptron\n",
        "    - Multilayer Perceptron\n",
        "4. [Keras MMP](#Q3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hJdTONSQAFGO"
      },
      "source": [
        "<a id=\"Q1\"></a>\n",
        "## 1. Define the following terms:\n",
        "\n",
        "- **Neuron:** They receive input and pass their signal to the next layer.\n",
        "- **Input Layer:** Where the data from our dataset goes into the neural network.\n",
        "- **Hidden Layer:** A layer where data is input to the layer and output comes out. We can't inspect what is happening because it is invisible. Helpful for learning about more complex relationships.\n",
        "- **Output Layer:** The layer where your answer is being held.\n",
        "- **Activation:** Decides where a cell \"fires\" or not. They also decide how much signal is passed onto the next layer.\n",
        "- **Backpropagation:** It's the process of updating the weights of the neural network, so that it can possibly be more accurate.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1PGCnIJ_AFGO"
      },
      "source": [
        "## 2. Chocolate Gummy Bears <a id=\"Q2\"></a>\n",
        "\n",
        "Right now, you're probably thinking, \"yuck, who the hell would eat that?\". Great question. Your candy company wants to know too. And you thought I was kidding about the [Chocolate Gummy Bears](https://nuts.com/chocolatessweets/gummies/gummy-bears/milk-gummy-bears.html?utm_source=google&utm_medium=cpc&adpos=1o1&gclid=Cj0KCQjwrfvsBRD7ARIsAKuDvMOZrysDku3jGuWaDqf9TrV3x5JLXt1eqnVhN0KM6fMcbA1nod3h8AwaAvWwEALw_wcB). \n",
        "\n",
        "Let's assume that a candy company has gone out and collected information on the types of Halloween candy kids ate. Our candy company wants to predict the eating behavior of witches, warlocks, and ghosts -- aka costumed kids. They shared a sample dataset with us. Each row represents a piece of candy that a costumed child was presented with during \"trick\" or \"treat\". We know if the candy was `chocolate` (or not chocolate) or `gummy` (or not gummy). Your goal is to predict if the costumed kid `ate` the piece of candy. \n",
        "\n",
        "If both chocolate and gummy equal one, you've got a chocolate gummy bear on your hands!?!?!\n",
        "![Chocolate Gummy Bear](https://ed910ae2d60f0d25bcb8-80550f96b5feb12604f4f720bfefb46d.ssl.cf1.rackcdn.com/3fb630c04435b7b5-2leZuM7_-zoom.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-voF0hoaAFGP",
        "inputHidden": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "outputHidden": false,
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "candy = pd.read_csv('chocolate_gummy_bears.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fxS-F1E1AFGR",
        "inputHidden": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "outputHidden": false,
        "outputId": "dde7e705-425c-4af2-f758-a11b2482f31e",
        "colab": {}
      },
      "source": [
        "candy.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chocolate</th>\n",
              "      <th>gummy</th>\n",
              "      <th>ate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   chocolate  gummy  ate\n",
              "0          0      1    1\n",
              "1          1      0    1\n",
              "2          0      1    1\n",
              "3          0      0    0\n",
              "4          1      1    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y9OryTxSAFGU",
        "outputId": "385cb145-5ef0-4f2a-dd6e-b7489373c4cf",
        "colab": {}
      },
      "source": [
        "candy.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xQRV77_KAFGV"
      },
      "source": [
        "### Perceptron\n",
        "\n",
        "To make predictions on the `candy` dataframe. Build and train a Perceptron using numpy. Your target column is `ate` and your features: `chocolate` and `gummy`. Do not do any feature engineering. :P\n",
        "\n",
        "Once you've trained your model, report your accuracy. Explain why you could not achieve a higher accuracy with a *simple perceptron*. It's possible to achieve ~95% accuracy on this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HfRfPaMLAFGW",
        "inputHidden": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "outputHidden": false,
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "# Start your candy perceptron here\n",
        "np.random.seed(69420)\n",
        "\n",
        "X = candy[['chocolate', 'gummy']].values\n",
        "y = candy['ate'].values\n",
        "\n",
        "weights = 2 * np.random.random((2,1)) - 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QsQIFxRBAFGY",
        "outputId": "e0c8851a-656c-40d3-cfb2-c1b82d2d39ce",
        "colab": {}
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 2), (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rtYttZBVAFGZ",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    sx = sigmoid(x)\n",
        "    return sx * (1 - sx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COMt7u0E6a76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Perceptron(object):\n",
        "    def __init__(self, rate=0.01, niter=10):\n",
        "        self.rate = rate\n",
        "        self.niter = niter\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        # weights\n",
        "        self.weight = np.zeros(1 + X.shape[1])\n",
        "        \n",
        "        # Number of missclassifications\n",
        "        self.errors = []\n",
        "        \n",
        "        for i in range(self.niter):\n",
        "            err = 0\n",
        "            for xi, target in zip(X, y):\n",
        "                delta_w = self.rate * (target - self.predict(xi))\n",
        "                self.weight[1:] += delta_w * xi\n",
        "                self.weight[0] += delta_w\n",
        "                err += int(delta_w !=0.0)\n",
        "            self.errors.append(err)\n",
        "        return self\n",
        "    \n",
        "    def net_input(self, X):\n",
        "        return np.dot(X, self.weight[1:]) + self.weight[0]\n",
        "    \n",
        "    def predict(self, X):\n",
        "        return np.where(self.net_input(X) >= 0.0, 1, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uOkFm9bhAFGb",
        "outputId": "b0faeb3c-d786-4e07-b438-7308c323a42d",
        "colab": {}
      },
      "source": [
        "for iteration in range(5):\n",
        "    weighted_sum = np.dot(X, weights)\n",
        "    \n",
        "    activated_output = sigmoid(weighted_sum)\n",
        "    \n",
        "    error = y - activated_output\n",
        "    \n",
        "    adjustments = error * sigmoid_derivative(activated_output)\n",
        "    \n",
        "    weights = weights + np.dot(X.T, adjustments)\n",
        "    \n",
        "print(\"weights\")\n",
        "print(weights)\n",
        "print(\"training output\")\n",
        "print(activated_output)\n",
        "print(\"actual output\")\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights\n",
            "[[613.41909554 613.41909554 613.41909554 ... 613.41909554 613.41909554\n",
            "  613.41909554]\n",
            " [670.59791588 670.59791588 670.59791588 ... 670.59791588 670.59791588\n",
            "  670.59791588]]\n",
            "training output\n",
            "[[1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " ...\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]]\n",
            "actual output\n",
            "[1 1 1 ... 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NBvwsvlVAFGc",
        "outputId": "f73f361d-cefc-4635-ca5f-fcbaea04a320",
        "colab": {}
      },
      "source": [
        "activated_output[0][0:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.00000000e+000, 1.00000000e+000, 1.00000000e+000, 1.45477193e-226,\n",
              "       1.45477193e-226, 1.00000000e+000, 1.45477193e-226, 1.45477193e-226,\n",
              "       1.45477193e-226, 1.45477193e-226])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tceJHtj86a8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Since this is just a simple perceptron, our accuracy is high because our baseline is high. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HWUOnQI6AFGf"
      },
      "source": [
        "### Multilayer Perceptron <a id=\"Q3\"></a>\n",
        "\n",
        "Using the sample candy dataset, implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights. Your Multilayer Perceptron should be implemented in Numpy. \n",
        "Your network must have one hidden layer.\n",
        "\n",
        "Once you've trained your model, report your accuracy. Explain why your MLP's performance is considerably better than your simple perceptron's on the candy dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sJfpI2i3AFGg",
        "colab": {}
      },
      "source": [
        "y = candy[['ate']].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IQHgFsuEAFGh",
        "inputHidden": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "outputHidden": false,
        "colab": {}
      },
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, inputs=2, hiddenNodes=4, outputNodes=1):\n",
        "        self.inputs = inputs\n",
        "        self.hiddenNodes = hiddenNodes\n",
        "        self.outputNodes = outputNodes\n",
        "        \n",
        "        self.weights1 = np.random.random((self.inputs, self.hiddenNodes))\n",
        "        self.weights2 = np.random.random((self.hiddenNodes, self.outputNodes))\n",
        "        \n",
        "    def sigmoid(self, s):\n",
        "        return 1 / (1 + np.exp(-s))\n",
        "    \n",
        "    def sigmoidPrime(self, s):\n",
        "        return s * (1 - s)\n",
        "    \n",
        "    def feed_forward(self, X):\n",
        "        self.hidden_sum = np.dot(X, self.weights1)\n",
        "        \n",
        "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
        "        \n",
        "        self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
        "        \n",
        "        self.activated_output = self.sigmoid(self.output_sum)\n",
        "        \n",
        "        return self.activated_output\n",
        "    \n",
        "    def backward(self, X, y, o):\n",
        "        \n",
        "        self.o_error = y - o\n",
        "        self.o_delta = self.o_error * self.sigmoidPrime(o)\n",
        "        \n",
        "        self.z2_error = self.o_delta.dot(self.weights2.T)\n",
        "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.activated_hidden)\n",
        "        \n",
        "        self.weights1 = self.weights1 + X.T.dot(self.z2_delta)\n",
        "        self.weights2 = self.weights2 + self.activated_hidden.T.dot(self.o_delta)\n",
        "        \n",
        "    def train(self, X, y):\n",
        "        o = self.feed_forward(X)\n",
        "        self.backward(X, y, o)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ir_YngtRAFGj",
        "outputId": "f40ae025-8e1e-4d7c-9735-ff8f99fa4176",
        "colab": {}
      },
      "source": [
        "# Training MLP\n",
        "nn = NeuralNetwork()\n",
        "\n",
        "# Number of Epochs / Iterations\n",
        "for i in range(10000):\n",
        "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 1000 ==0):\n",
        "        print('-----' * 2 + f'EPOCH {i+1}' + '-----' * 2)\n",
        "        print('Input: \\n', X)\n",
        "        print('Actual Output: \\n', y)\n",
        "        print('Predicted Output: \\n', str(nn.feed_forward(X)))\n",
        "        print(\"Loss: \\n\", str(np.mean(np.square(y - nn.feed_forward(X)))))\n",
        "    nn.train(X, y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------EPOCH 1----------\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.72380462]\n",
            " [0.71155978]\n",
            " [0.72380462]\n",
            " ...\n",
            " [0.72380462]\n",
            " [0.72380462]\n",
            " [0.71155978]]\n",
            "Loss: \n",
            " 0.29606941798280395\n",
            "----------EPOCH 2----------\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.24516033]\n",
            " [0.0500345 ]\n",
            " [0.24516033]\n",
            " ...\n",
            " [0.24516033]\n",
            " [0.24516033]\n",
            " [0.0500345 ]]\n",
            "Loss: \n",
            " 0.4241596963382991\n",
            "----------EPOCH 3----------\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.49997392]\n",
            " [0.49994386]\n",
            " [0.49997392]\n",
            " ...\n",
            " [0.49997392]\n",
            " [0.49997392]\n",
            " [0.49994386]]\n",
            "Loss: \n",
            " 0.20116832629025336\n",
            "----------EPOCH 4----------\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.49997466]\n",
            " [0.49994721]\n",
            " [0.49997466]\n",
            " ...\n",
            " [0.49997466]\n",
            " [0.49997466]\n",
            " [0.49994721]]\n",
            "Loss: \n",
            " 0.20116741545923628\n",
            "----------EPOCH 5----------\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.49997536]\n",
            " [0.49995018]\n",
            " [0.49997536]\n",
            " ...\n",
            " [0.49997536]\n",
            " [0.49997536]\n",
            " [0.49995018]]\n",
            "Loss: \n",
            " 0.2011665996864868\n",
            "----------EPOCH 1000----------\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.49999898]\n",
            " [0.49999879]\n",
            " [0.49999898]\n",
            " ...\n",
            " [0.49999898]\n",
            " [0.49999898]\n",
            " [0.49999879]]\n",
            "Loss: \n",
            " 0.20115049612155847\n",
            "----------EPOCH 2000----------\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.49999943]\n",
            " [0.49999931]\n",
            " [0.49999943]\n",
            " ...\n",
            " [0.49999943]\n",
            " [0.49999943]\n",
            " [0.49999931]]\n",
            "Loss: \n",
            " 0.2011502818684513\n",
            "----------EPOCH 3000----------\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.49999959]\n",
            " [0.4999995 ]\n",
            " [0.49999959]\n",
            " ...\n",
            " [0.49999959]\n",
            " [0.49999959]\n",
            " [0.4999995 ]]\n",
            "Loss: \n",
            " 0.20115020304005446\n",
            "----------EPOCH 4000----------\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.49999967]\n",
            " [0.49999961]\n",
            " [0.49999967]\n",
            " ...\n",
            " [0.49999967]\n",
            " [0.49999967]\n",
            " [0.49999961]]\n",
            "Loss: \n",
            " 0.20115016075668102\n",
            "----------EPOCH 5000----------\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.49999973]\n",
            " [0.49999967]\n",
            " [0.49999973]\n",
            " ...\n",
            " [0.49999973]\n",
            " [0.49999973]\n",
            " [0.49999967]]\n",
            "Loss: \n",
            " 0.20115013397996875\n",
            "----------EPOCH 6000----------\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.49999976]\n",
            " [0.49999972]\n",
            " [0.49999976]\n",
            " ...\n",
            " [0.49999976]\n",
            " [0.49999976]\n",
            " [0.49999972]]\n",
            "Loss: \n",
            " 0.2011501153419363\n",
            "----------EPOCH 7000----------\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.49999979]\n",
            " [0.49999975]\n",
            " [0.49999979]\n",
            " ...\n",
            " [0.49999979]\n",
            " [0.49999979]\n",
            " [0.49999975]]\n",
            "Loss: \n",
            " 0.20115010154806556\n",
            "----------EPOCH 8000----------\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.49999981]\n",
            " [0.49999978]\n",
            " [0.49999981]\n",
            " ...\n",
            " [0.49999981]\n",
            " [0.49999981]\n",
            " [0.49999978]]\n",
            "Loss: \n",
            " 0.20115009088898914\n",
            "----------EPOCH 9000----------\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.49999983]\n",
            " [0.4999998 ]\n",
            " [0.49999983]\n",
            " ...\n",
            " [0.49999983]\n",
            " [0.49999983]\n",
            " [0.4999998 ]]\n",
            "Loss: \n",
            " 0.20115008238360374\n",
            "----------EPOCH 10000----------\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.49999984]\n",
            " [0.49999982]\n",
            " [0.49999984]\n",
            " ...\n",
            " [0.49999984]\n",
            " [0.49999984]\n",
            " [0.49999982]]\n",
            "Loss: \n",
            " 0.20115007542598878\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tfUyUwjrAFGk"
      },
      "source": [
        "P.S. Don't try candy gummy bears. They're disgusting. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bIbyelUFAFGl"
      },
      "source": [
        "#### 0.2 is acceptable, I guess."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rjfsBaGlAFGl"
      },
      "source": [
        "## 3. Keras MMP <a id=\"Q3\"></a>\n",
        "\n",
        "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
        "Use the Heart Disease Dataset (binary classification)\n",
        "Use an appropriate loss function for a binary classification task\n",
        "Use an appropriate activation function on the final layer of your network.\n",
        "Train your model using verbose output for ease of grading.\n",
        "Use GridSearchCV or RandomSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
        "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
        "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
        "You must hyperparameter tune at least 3 parameters in order to get a 3 on this section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SuBddgOzAFGm",
        "inputHidden": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "outputHidden": false,
        "outputId": "f0c37e68-e2c8-4bdd-fafc-290ef8e96098",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
        "df = df.sample(frac=1)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(303, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>140</td>\n",
              "      <td>335</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>158</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>135</td>\n",
              "      <td>203</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>132</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>145</td>\n",
              "      <td>307</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>146</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>42</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>226</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>221</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>163</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
              "177   64    1   2       140   335    0        1      158      0      0.0   \n",
              "63    41    1   1       135   203    0        1      132      0      0.0   \n",
              "213   61    0   0       145   307    0        0      146      1      1.0   \n",
              "22    42    1   0       140   226    0        1      178      0      0.0   \n",
              "159   56    1   1       130   221    0        0      163      0      0.0   \n",
              "\n",
              "     slope  ca  thal  target  \n",
              "177      2   0     2       0  \n",
              "63       1   0     1       1  \n",
              "213      1   0     3       0  \n",
              "22       2   0     2       1  \n",
              "159      2   0     3       1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cYo9gsQOAFGn",
        "outputId": "36535bca-2485-470f-91d2-37cd3d1dc5ed",
        "colab": {}
      },
      "source": [
        "df.target.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    165\n",
              "0    138\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C-ck1T2rAFGp",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "X = df.drop(columns='target').values\n",
        "y = df[['target']].values\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(x_train)\n",
        "X_test = scaler.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H9sFueBmAFGq",
        "colab": {},
        "outputId": "07e85f71-2d9d-4870-b2c8-1c394fcd4dc3"
      },
      "source": [
        "!pip install tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "  Downloading https://files.pythonhosted.org/packages/54/5f/e1b2d83b808f978f51b7ce109315154da3a3d4151aa59686002681f2e109/tensorflow-2.0.0-cp37-cp37m-win_amd64.whl (48.1MB)\n",
            "Collecting grpcio>=1.8.6 (from tensorflow)\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/e5/79974f0288e36be3205e71f91e0dbe2a5746ccaa84780c65c4d75fa4b269/grpcio-1.24.1-cp37-cp37m-win_amd64.whl (1.6MB)\n",
            "Collecting google-pasta>=0.1.6 (from tensorflow)\n",
            "  Downloading https://files.pythonhosted.org/packages/d0/33/376510eb8d6246f3c30545f416b2263eee461e40940c2a4413c711bdf62d/google_pasta-0.1.7-py3-none-any.whl (52kB)\n",
            "Collecting gast==0.2.2 (from tensorflow)\n",
            "Collecting astor>=0.6.0 (from tensorflow)\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
            "Collecting keras-preprocessing>=1.0.5 (from tensorflow)\n",
            "  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0 (from tensorflow)\n",
            "  Downloading https://files.pythonhosted.org/packages/95/00/5e6cdf86190a70d7382d320b2b04e4ff0f8191a37d90a422a2f8ff0705bb/tensorflow_estimator-2.0.0-py2.py3-none-any.whl (449kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.4)\n",
            "Requirement already satisfied: wheel>=0.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.33.4)\n",
            "Collecting termcolor>=1.1.0 (from tensorflow)\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
            "Collecting tensorboard<2.1.0,>=2.0.0 (from tensorflow)\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/a6/e8ffa4e2ddb216449d34cfcb825ebb38206bee5c4553d69e7bc8bc2c5d64/tensorboard-2.0.0-py3-none-any.whl (3.8MB)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied: six>=1.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.0)\n",
            "Collecting protobuf>=3.6.1 (from tensorflow)\n",
            "  Downloading https://files.pythonhosted.org/packages/a8/ae/a11b9b0c8e2410b11887881990b71f54ec39b17c4de2b5d850ef66aade8c/protobuf-3.10.0-cp37-cp37m-win_amd64.whl (1.0MB)\n",
            "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/83/755bd5324777875e9dff19c2e59daec837d0378c09196634524a3d7269ac/opt_einsum-3.1.0.tar.gz (69kB)\n",
            "Collecting keras-applications>=1.0.8 (from tensorflow)\n",
            "  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "Collecting absl-py>=0.7.0 (from tensorflow)\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/72/e6e483e2db953c11efa44ee21c5fdb6505c4dffa447b4263ca8af6676b62/absl-py-0.8.1.tar.gz (103kB)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.15.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (41.0.1)\n",
            "Collecting markdown>=2.6.8 (from tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
            "  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
            "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow) (2.9.0)\n",
            "Building wheels for collected packages: termcolor, opt-einsum, absl-py\n",
            "  Building wheel for termcolor (setup.py): started\n",
            "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
            "  Stored in directory: C:\\Users\\macky\\AppData\\Local\\pip\\Cache\\wheels\\7c\\06\\54\\bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
            "  Building wheel for opt-einsum (setup.py): started\n",
            "  Building wheel for opt-einsum (setup.py): finished with status 'done'\n",
            "  Stored in directory: C:\\Users\\macky\\AppData\\Local\\pip\\Cache\\wheels\\2c\\b1\\94\\43d03e130b929aae7ba3f8d15cbd7bc0d1cb5bb38a5c721833\n",
            "  Building wheel for absl-py (setup.py): started\n",
            "  Building wheel for absl-py (setup.py): finished with status 'done'\n",
            "  Stored in directory: C:\\Users\\macky\\AppData\\Local\\pip\\Cache\\wheels\\a7\\15\\a0\\0a0561549ad11cdc1bc8fa1191a353efd30facf6bfb507aefc\n",
            "Successfully built termcolor opt-einsum absl-py\n",
            "Installing collected packages: grpcio, google-pasta, gast, astor, keras-preprocessing, tensorflow-estimator, termcolor, absl-py, protobuf, markdown, tensorboard, opt-einsum, keras-applications, tensorflow\n",
            "Successfully installed absl-py-0.8.1 astor-0.8.0 gast-0.2.2 google-pasta-0.1.7 grpcio-1.24.1 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 opt-einsum-3.1.0 protobuf-3.10.0 tensorboard-2.0.0 tensorflow-2.0.0 tensorflow-estimator-2.0.0 termcolor-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zirIPTXQAFGs",
        "outputId": "d1c2b42b-2254-4b1b-f0d2-f0cf2bf96ee8",
        "colab": {}
      },
      "source": [
        "def create_model(learning_rate = 0.01):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(14, input_dim=13, activation='relu'))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "       \n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "param_grid ={'batch_size': [10, 50, 100, 200],\n",
        "            'epochs': [10],\n",
        "            'learning_rate': [.01],\n",
        "            }\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.7241379231067714 using {'batch_size': 10, 'epochs': 10, 'learning_rate': 0.01}\n",
            "Means: 0.7241379231067714, Stdev: 0.03876268104706246 with: {'batch_size': 10, 'epochs': 10, 'learning_rate': 0.01}\n",
            "Means: 0.5911330008154432, Stdev: 0.02795490678553894 with: {'batch_size': 50, 'epochs': 10, 'learning_rate': 0.01}\n",
            "Means: 0.6305418610572815, Stdev: 0.10143038490289724 with: {'batch_size': 100, 'epochs': 10, 'learning_rate': 0.01}\n",
            "Means: 0.5566502438096578, Stdev: 0.1059594608381056 with: {'batch_size': 200, 'epochs': 10, 'learning_rate': 0.01}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oKd4hdBTAFG1",
        "outputId": "6608a43d-3c76-45c8-de86-416a8adf3c7c",
        "colab": {}
      },
      "source": [
        "def create_model(learning_rate = 0.01):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(14, input_dim=13, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    \n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "param_grid ={'batch_size': [100],\n",
        "            'epochs': [50],\n",
        "            'learning_rate': [1, .1, .01],\n",
        "            }\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.7881773595739467 using {'batch_size': 100, 'epochs': 50, 'learning_rate': 1}\n",
            "Means: 0.7881773595739467, Stdev: 0.026166544045345456 with: {'batch_size': 100, 'epochs': 50, 'learning_rate': 1}\n",
            "Means: 0.7684728964208969, Stdev: 0.019691996751114833 with: {'batch_size': 100, 'epochs': 50, 'learning_rate': 0.1}\n",
            "Means: 0.7881773507653786, Stdev: 0.014714384541885745 with: {'batch_size': 100, 'epochs': 50, 'learning_rate': 0.01}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cv0TgiUZ6a8Y",
        "colab_type": "code",
        "colab": {},
        "outputId": "5d340bc7-a5da-4a6f-ff89-8e3472157bcc"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = grid_result.best_estimator_.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.76\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}